{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd7a7ab7-e524-4c52-aeda-5c4873560062",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Assignment 3\n",
    "\n",
    "In this assignment, you are to experiment with embedding vectors of words and training of a recurrent neural network for sentence classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e259fd3-1666-40ff-9b9f-c05550d92fd2",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "source": [
    "## 1. Loading dataset\n",
    "\n",
    "The dataset comes from https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset\n",
    "\n",
    "It contains 120,000 news articles that are labeled into four categories:\n",
    "\n",
    "- 1: world news\n",
    "- 2: sports\n",
    "- 3: business\n",
    "- 4: science and technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76dbb165-27e9-4802-b306-42a9edf93901",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_setup_datasets() got an unexpected keyword argument 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m train_iter \u001b[38;5;241m=\u001b[39m \u001b[43mtorchtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAG_NEWS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./datasets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m train_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m      8\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_iter)),\n\u001b[1;32m      9\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFive randomly selected samples:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.12/site-packages/torchtext/datasets/text_classification.py:170\u001b[0m, in \u001b[0;36mAG_NEWS\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mAG_NEWS\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    146\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Defines AG_NEWS datasets.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        The labels includes:\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m            - 1 : World\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m \n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_setup_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAG_NEWS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: _setup_datasets() got an unexpected keyword argument 'split'"
     ]
    }
   ],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "import torchtext.datasets\n",
    "import pandas as pd\n",
    "\n",
    "train_iter = torchtext.datasets.AG_NEWS(root='./datasets', split='train')\n",
    "\n",
    "train_df = pd.DataFrame(\n",
    "    data=list(iter(train_iter)),\n",
    "    columns=['target', 'news'],\n",
    ")\n",
    "\n",
    "print(\"Five randomly selected samples:\")\n",
    "print(train_df.sample(5, random_state=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9356a3-c9eb-4077-9785-ebf37196f0ca",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 2. Tokenizer\n",
    "\n",
    "ðŸš¨ Instruction:\n",
    "> Load the `basic_english` tokenizer using the `get_tokenizer` from `torchtext.data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0bf069-46af-404d-8dd6-c7ee73ae59b9",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "import torchtext.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dee8c07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [YOUR WORK HERE]\n",
    "# @workUnit\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a4a7fe-505a-4a45-a962-8b3ae6ea9d7c",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "# @check\n",
    "# @title: tokenizer\n",
    "\n",
    "type(tokenizer), tokenizer.__qualname__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9574e2c-b404-42b9-9745-cdade756ded0",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "# @check\n",
    "# @title: tokens of sentence\n",
    "tokenizer(\"This is assignment 3 for csci 4050u.  It's on sequence learning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259adc41-d58c-4e5d-9da8-35700d83fb60",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 3. Vocabulary\n",
    "\n",
    "Token sequence is a list of tokens.  We need to vocabulary to convert each\n",
    "token into an integer, known as the token index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a3a86e-42b8-4f4b-83d8-dcfe1f1e896f",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "# construct token sequence\n",
    "# this is a collection of token sequences.\n",
    "# Every sentence is converted to a token sequence by the tokenizer.\n",
    "\n",
    "token_seq = map(tokenizer, train_df['news'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b7cea-69b9-481a-9ae7-efc3bb8ed31b",
   "metadata": {
    "editable": false
   },
   "source": [
    "ðŸš¨ Instruction:\n",
    "\n",
    "> Use the `build_vocab_from_iterator` helper function from `torchtext.vocab` to construct\n",
    "the vocabulary from the `token_seq`.\n",
    "\n",
    "> Make sure you set the `min_freq=5` and special tokens should be `['<unk>', '<s>']`.\n",
    "The first token index `0` corresponds to unknown token `<unk>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9ec306-16d6-4dd7-bd46-48aed159b8d5",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "import torchtext.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc93dcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [YOUR WORK HERE]\n",
    "# @workUnit\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "vocab = vocab = build_vocab_from_iterator(\n",
    "    token_seq,  # token_seq is the iterator over tokenized sentences\n",
    "    min_freq=5,  # Minimum frequency for tokens to be included in the vocabulary\n",
    "    specials=['<unk>', '<s>']  # Special tokens: <unk> for unknown and <s> for sentence start\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c3b59-b8cf-40e0-87f3-7d4cbd43ef3c",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "# if token is not in vocabulary, use the index 0.\n",
    "vocab.set_default_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c953ae41-45be-4d7d-b5c2-bfd4368d88f8",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "# @check\n",
    "# @title: length of the vocab\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee2c55-6209-4ddc-af99-2ab33c1f1776",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "# @check\n",
    "# @title: lookup token indexes using vocab\n",
    "\n",
    "vocab.lookup_indices(tokenizer(\"this is an assignment for csci 4050u.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f7106-2495-4d6b-9600-bfe0fd056141",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "# @check\n",
    "# @title: lookup token string value using vocab\n",
    "\n",
    "vocab.lookup_tokens([53, 22, 31, 10659, 12, 0, 0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd569b1d-ec82-4fc9-b16a-d8a4b72b7d4a",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 4. Integer encoding\n",
    "\n",
    "Now, we are ready to encode news article sentences into sequences of integers. \n",
    "\n",
    "ðŸš¨ Instruction:\n",
    "\n",
    "> create a list of `torch.int64` tensors.  Each of the tensor is a vector of int64 integers which are the token indexes of the tokens of sentences in the\n",
    "> training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c6b25-3cd7-460d-8983-adede1175f73",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abaf897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [YOUR WORK HERE]\n",
    "# @workUnit\n",
    "\n",
    "index_sequences = [\n",
    "    torch.tensor(vocab.lookup_indices(tokenizer(review)), dtype=torch.int64)\n",
    "    for review in train_df['news']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da246c65-f7a1-4842-a653-1a432e8cc2dd",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "# @check\n",
    "# @title: return types\n",
    "\n",
    "print(f\"Type of index_sequences: {type(index_sequences)}\")\n",
    "print(f\"Type of elements in index_sequences: {type(index_sequences[0])} with dtype {index_sequences[0].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd85587-1d58-47ac-ae4f-f73de2bf3909",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "# @check\n",
    "# @title: number of index sequences\n",
    "\n",
    "len(index_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbaff2e-57aa-4fb4-8e42-80ac333478db",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "# @check\n",
    "# @title: first three index sequences\n",
    "\n",
    "for i in range(3):\n",
    "    sentence = train_df.iloc[i].news\n",
    "    index_sequence = index_sequences[i]\n",
    "    print(sentence)\n",
    "    print(index_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39013cca-904b-4480-994b-cbebcee94b47",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 5. Prepare token index tensor\n",
    "\n",
    "Now, we are ready to prepare the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0db2f9-0bab-4fe7-95a6-cc0703ba7f05",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b0672-ead9-4e2c-9d86-b7f963f63180",
   "metadata": {
    "editable": false
   },
   "source": [
    "- First we will need to pad each sequence in index_sequences so\n",
    "they are all match the *longest* sequence.\n",
    "\n",
    "- Then, we wil truncate each sequence to keep only the first 100 tokens.\n",
    "  This is to remove the noise of the few extra long articles.  Basically,\n",
    "  we will classify the article using only the first 100 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269cd78f-6206-499d-b31d-f99fd052bfc4",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "padded_sequences = pad_sequence(index_sequences, batch_first=True)\n",
    "print(\"After padding:\", padded_sequences.shape)\n",
    "\n",
    "padded_sequences = padded_sequences[:, :100]\n",
    "print(\"After truncation:\", padded_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1463e0-e781-4303-af01-caeb7bfcdf48",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 6. Prepare training and validation tensors\n",
    "\n",
    "We can now prepare training and validation datasets for RNN training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b13a30d-681b-42e0-a58e-ce420fb371c2",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "from torch.utils.data import (\n",
    "    TensorDataset,\n",
    "    random_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725488df-61e8-47fe-b9e3-588b6cfd933e",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "#\n",
    "# targets\n",
    "#\n",
    "\n",
    "targets = torch.tensor(train_df['target'] - 1, dtype=torch.int64)\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463797f5-e64a-4e48-965f-973483fc859e",
   "metadata": {
    "editable": false
   },
   "source": [
    "ðŸš¨ Instructions:\n",
    "\n",
    "- Create the dataset from `padded_sequences` and `targets` using `TensorData`\n",
    "- Create training and validation dataset using `random_split`.  Use 30% of the dataset for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97303d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [YOUR WORK HERE]\n",
    "# @workUnit\n",
    "\n",
    "# IMPORTANT: keep this line to pass the checkpoints.\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#\n",
    "# dataset for training and validation\n",
    "#\n",
    "\n",
    "dataset = ...\n",
    "\n",
    "(train_dataset, val_dataset) = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8433cbb-56d3-4087-9fc1-5c2692818669",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "# @check\n",
    "# @title: training and validation dataset sizes\n",
    "\n",
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb07d7-3a3d-43ba-ad94-9fb1f8ddf3c4",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "# @check\n",
    "# @title: training sample\n",
    "\n",
    "print(\"Training sample:\")\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a89c8-82b7-4078-86aa-81e6828be7e8",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "# @check\n",
    "# @title: validation sample\n",
    "\n",
    "print(\"Validation sample:\")\n",
    "print(val_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a12406f-cb72-4cb9-a577-480de1ee6ced",
   "metadata": {
    "editable": false
   },
   "source": [
    "# INSTRUCTION\n",
    "\n",
    "## ðŸ“¢ For the remainder of the worksheet, you must understand the code provided.  But no workUnits are required.\n",
    "\n",
    "## ðŸš¨ You must execute all cells and obtain the performance comparison plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131fd291-ee0d-4207-b992-9877b623bbfc",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 7. Simple RNN Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880458ae-def9-4c5e-b974-9abfe584b4bb",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "import torch.nn as nn\n",
    "from lightning.pytorch import LightningModule\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "num_layers = 1\n",
    "num_classes = 4\n",
    "\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, d_emb, d_state):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, d_emb)\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=d_emb,\n",
    "            hidden_size=d_state,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.output = nn.Linear(d_state, num_classes)\n",
    "        self.accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "            \n",
    "    def forward(self, batch_of_sequences):\n",
    "        embeddings = self.emb(batch_of_sequences)\n",
    "        _, final_states = self.rnn(embeddings)\n",
    "        final_state = final_states[-1]\n",
    "        logits = self.output(final_state)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17944761-72cc-4d03-b305-1ba83965c50f",
   "metadata": {
    "editable": false
   },
   "source": [
    "Let's try out the basic RNN (not yet trained) on a sample batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdcfefc-3c5a-4ac3-9d8a-c4b15d4060d9",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "# @check\n",
    "# @title: untrained model checking\n",
    "\n",
    "model = MyRNN(d_emb=128, d_state=64)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d6641-ff04-4a99-9369-6ec418d3f578",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "# @check\n",
    "# @title: untrained model checking\n",
    "\n",
    "model = MyRNN(d_emb=128, d_state=64)\n",
    "x, target = dataset[:32]\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc1efa-ef74-4f29-8662-6f44a2d37f1d",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "source": [
    "## 8. Simple RNN Lightning Module\n",
    "\n",
    "Add the Lightning logging methods to `MyRNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bb8754-fc21-429b-b8b8-4c0e5e0eede5",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "class MyLightning(LightningModule):        \n",
    "    def training_step(self, batch_of_sequences):\n",
    "        x, target = batch_of_sequences\n",
    "        y = self.forward(x)\n",
    "        loss = nn.functional.cross_entropy(y, target)\n",
    "        self.accuracy(y, target)\n",
    "        self.log('accuracy', self.accuracy, prog_bar=True)\n",
    "        self.log('loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "    \n",
    "    def validation_step(self, batch, batch_index):\n",
    "        x, target = batch\n",
    "        y = self.forward(x)\n",
    "        self.accuracy(y, target)\n",
    "        self.log('val_acc', self.accuracy, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ffcca8-bca1-42eb-975f-fceff85ed4f8",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "class MyLightningRNN(MyRNN, MyLightning):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d37fec8-56ac-4b73-8aa2-5350fdb4a683",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 9. Create a trainer utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d7f77-8b61-49aa-9cb9-067a8dae1398",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning import seed_everything\n",
    "from torch.utils.data import DataLoader\n",
    "import shutil, os\n",
    "import time\n",
    "\n",
    "#\n",
    "# initialize logger\n",
    "#\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "def train(*, name:str, model:LightningModule, epochs:int, debug=True):\n",
    "    # reset the random generator\n",
    "    seed_everything(0)\n",
    "    \n",
    "    # create CSV logger\n",
    "    logger = CSVLogger('./lightning_logs/', name)\n",
    "        \n",
    "    # create trainer\n",
    "    trainer = Trainer(\n",
    "        logger = logger,\n",
    "        max_epochs = epochs,\n",
    "        max_steps = 100 if debug else -1\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        shutil.rmtree(f\"./lightning_logs/{name}\")\n",
    "        os.mkdirs(f\"./lightning_logs/{name}\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # start trainer\n",
    "    start = time.time()\n",
    "    trainer.fit(\n",
    "            model=model,\n",
    "            train_dataloaders=train_dataloader,\n",
    "            val_dataloaders=val_dataloader\n",
    "    )\n",
    "    duration = (time.time() - start)\n",
    "    print(f\"Completed {epochs} epochs in {duration:0.2f} seconds.\")\n",
    "    print(trainer.validate(model, dataloaders = val_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32cbe4-c75f-4e41-9af1-3b4ff53da312",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 10. Train some RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0711afa1-0578-4875-8cff-57b0f9cd38b0",
   "metadata": {
    "editable": false
   },
   "source": [
    "ðŸ“¢ Instruction\n",
    "\n",
    "- You are encouraged to play with the parameters:\n",
    "\n",
    "> - `d_emb`\n",
    "> - `d_state`\n",
    "> - `epochs`\n",
    "\n",
    "ðŸ“¢ Note:\n",
    "\n",
    "- For `d_emb=8, d_state=16`, it takes 50 seconds per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96eb4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [YOUR WORK HERE]\n",
    "# @workUnit\n",
    "\n",
    "seed_everything(0)\n",
    "\n",
    "train(\n",
    "    name='rnn',\n",
    "    model = MyLightningRNN(d_emb=8, d_state=16),\n",
    "    epochs=5,\n",
    "    debug=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311e9a3f-9e62-495f-8d02-6324a6e45807",
   "metadata": {
    "editable": false
   },
   "source": [
    "We will now enhance the RNN classifier with a more advanced architecture for the cell -- namely the LSTM design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e70f1-8fa5-4fbd-8818-b33bd1fe9ac3",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Extending RNN to LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90010371-5f77-4751-88d2-f44c97871c56",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, d_emb, d_state):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_emb)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=d_emb,\n",
    "                          hidden_size=d_state,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.output = nn.Linear(d_state, num_classes)\n",
    "        \n",
    "        # will be monitoring accuracy\n",
    "        self.accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (states, _) = self.lstm(x)\n",
    "        states = states[-1]\n",
    "        return self.output(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b280be-8d3b-4e58-9e40-48f01717a869",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "class MyLightningLSTM(MyLSTM, MyLightning):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aad309-13e0-4d79-be4c-9147083448b8",
   "metadata": {
    "editable": false
   },
   "source": [
    "ðŸ“¢ Instruction\n",
    "\n",
    "- You are encouraged to play with the parameters:\n",
    "\n",
    "> - `d_emb`\n",
    "> - `d_state`\n",
    "> - `epochs`\n",
    "\n",
    "ðŸ“¢ Note:\n",
    "\n",
    "- For `d_emb=8, d_state=16`, it takes 30 seconds per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7163e63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [YOUR WORK HERE]\n",
    "# @workUnit\n",
    "\n",
    "seed_everything(0)\n",
    "\n",
    "train(\n",
    "    name = 'lstm',\n",
    "    model = MyLightningLSTM(d_emb=8, d_state=16),\n",
    "    epochs = 5,\n",
    "    debug = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb2f42c-5e26-4ea4-ab06-7dd9fbafdfac",
   "metadata": {
    "editable": false
   },
   "source": [
    "## 11. Performance comparison\n",
    "\n",
    "- Lightning logs the performance metrics in `./lightning_logs/{name}/{version}/metrics.csv`.\n",
    "- We can load the metrics into pandas dataframes and plot the validation accuracy over runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e77de6-450f-4c23-9b21-ab9a9492d6d6",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "perf_rnn = pd.read_csv('./lightning_logs/rnn/version_0/metrics.csv')\n",
    "perf_lstm = pd.read_csv('./lightning_logs/lstm/version_0/metrics.csv')\n",
    "val_acc = pd.concat([perf_rnn.val_acc.dropna(), perf_lstm.val_acc.dropna()], axis=1)\n",
    "val_acc.columns = ['rnn', 'lstm']\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c01f752-20c6-423d-9b14-557f6ba84f58",
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(val_acc.index, val_acc.rnn, '--+', val_acc.index, val_acc.lstm, '-o')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Validation accuracy')\n",
    "plt.legend(['RNN', 'LSTM']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9844308-acf1-4c44-8c69-9179eb800268",
   "metadata": {
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [THIS IS READ-ONLY]\n",
    "loss = pd.concat([perf_rnn.loss.dropna(), perf_lstm.loss.dropna()], axis=1)\n",
    "loss.columns = ['rnn', 'lstm']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss.index, loss.rnn, '--+', loss.index, loss.lstm, '-o')\n",
    "plt.title('Training loss')\n",
    "plt.legend(['RNN', 'LSTM']);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
